{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS MODULE\n",
    "\n",
    "import operator\n",
    "\n",
    "\n",
    "class RefPath:\n",
    "    INITIAL = \"#/info/x-clusters/\"\n",
    "    WORKER_NODES = \"worker-nodes\"\n",
    "    PODS = \"pods\"\n",
    "    CONTAINERS = \"containers\"\n",
    "    INFO = \"info\"\n",
    "    X_CLUSTERS = \"x-clusters\"\n",
    "    X_LOCATION = \"x-location\"\n",
    "    REF = \"$ref\"\n",
    "    PATHS = \"paths\"\n",
    "\n",
    "    def __init__(self, *arg):\n",
    "        if len(arg) == 1:\n",
    "            paths = arg[0].split(\"#/info/x-clusters/\")\n",
    "            parts = paths[1].split(\"/\")\n",
    "            self.cluster = parts[0]\n",
    "            self.worker_node = parts[2]\n",
    "            self.pod_name = parts[4]\n",
    "            self.container_name = parts[6]\n",
    "        else:\n",
    "            self.cluster = arg[0]\n",
    "            self.worker_node = arg[1]\n",
    "            self.pod_name = arg[2]\n",
    "            self.container_name = arg[3]\n",
    "\n",
    "    @property\n",
    "    def full_path(self):\n",
    "        return f\"{RefPath.INITIAL}{self.cluster}/{RefPath.WORKER_NODES}/{self.worker_node}/{RefPath.PODS}/\" \\\n",
    "               f\"{self.pod_name}/{RefPath.CONTAINERS}/{self.container_name}\"\n",
    "\n",
    "\n",
    "class Method:\n",
    "    def __init__(self, path_name, method_name, ref_path, load, schema_name, full_method):\n",
    "        self.path_name = path_name\n",
    "        self.method_name = method_name\n",
    "        self.ref_path = ref_path\n",
    "        self.load = load\n",
    "        self.schema_name = schema_name\n",
    "        self.full_method = full_method\n",
    "        self.contribution = 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.path_name + \": \" + self.method_name + \" (\" + self.ref_path.full_path + \") \" + str(\n",
    "            self.load) + \" <-> \" + self.schema_name\n",
    "\n",
    "\n",
    "class Component:\n",
    "    def __init__(self, name, load, full_component, ref_path=None, is_new=False):\n",
    "        self.name = name\n",
    "        self.load = load\n",
    "        self.full_component = full_component\n",
    "        self.ref_path = ref_path\n",
    "        self.is_new = is_new\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name + \" ---- \" + str(self.load) + \" (\" + self.ref_path + \") \" + \"New ? \" + str(self.is_new)\n",
    "\n",
    "\n",
    "class Group:\n",
    "    def __init__(self, parent_load, sum_of_loads, components):\n",
    "        self.parent_load = parent_load\n",
    "        self.sum_of_loads = sum_of_loads\n",
    "        self.components = components\n",
    "\n",
    "    def get_contributed_components(self):\n",
    "        components = []\n",
    "        for component in self.components:\n",
    "            component.contribution = (component.load / self.sum_of_loads) * self.parent_load\n",
    "            components.append(component)\n",
    "        return sorted(components, key=operator.attrgetter(\"contribution\"))\n",
    "\n",
    "\n",
    "class Cluster(Component):\n",
    "    def __init__(self, name, load, full_component, ref_path, is_new=False):\n",
    "        super().__init__(name, load, full_component, ref_path, is_new)\n",
    "        self.is_cluster = True\n",
    "\n",
    "    @property\n",
    "    def worker_nodes(self):\n",
    "        worker_nodes = []\n",
    "        for wn in self.full_component[\"worker-nodes\"].values():\n",
    "            ref_path = self.ref_path + \"/worker-nodes/\" + wn[\"name\"]\n",
    "            worker_nodes.append(WorkerNode(wn[\"name\"], wn[\"metrics\"][\"load\"], wn, ref_path))\n",
    "        return worker_nodes\n",
    "\n",
    "\n",
    "class WorkerNode(Component):\n",
    "    def __init__(self, name, load, full_component, ref_path, is_new=False):\n",
    "        super().__init__(name, load, full_component, ref_path, is_new)\n",
    "        self.is_worker_node = True\n",
    "\n",
    "    @property\n",
    "    def pods(self):\n",
    "        pods = []\n",
    "        for pod in self.full_component[\"pods\"].values():\n",
    "            ref_path = self.ref_path + \"/pods/\" + pod[\"name\"]\n",
    "            pods.append(Pod(pod[\"name\"], pod[\"metrics\"][\"load\"], pod, ref_path))\n",
    "        return pods\n",
    "\n",
    "\n",
    "class Pod(Component):\n",
    "    def __init__(self, name, load, full_component, ref_path, is_new=False):\n",
    "        super().__init__(name, load, full_component, ref_path, is_new)\n",
    "        self.is_pod = True\n",
    "        self.contribution = 0\n",
    "\n",
    "    @property\n",
    "    def containers(self):\n",
    "        containers = []\n",
    "        for container_name, container in self.full_component[\"containers\"].items():\n",
    "            ref_path = self.ref_path + \"/containers/\" + container_name\n",
    "            containers.append(Container(container_name, container[\"metrics\"][\"load\"], container, ref_path))\n",
    "        return containers\n",
    "\n",
    "\n",
    "class Container(Component):\n",
    "    def __init__(self, name, load, full_component, ref_path, is_new=False):\n",
    "        super().__init__(name, load, full_component, ref_path, is_new)\n",
    "        self.is_container = True\n",
    "\n",
    "\n",
    "class PodGroup(Group):\n",
    "    def __init__(self, parent_load, sum_of_loads, components):\n",
    "        super().__init__(parent_load, sum_of_loads, components)\n",
    "        self.is_pod_group = True\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"PodGroup sum_of_loads: \" + str(self.sum_of_loads)\n",
    "\n",
    "\n",
    "class ContainerGroup(Group):\n",
    "    def __init__(self, parent_load, sum_of_loads, components):\n",
    "        super().__init__(parent_load, sum_of_loads, components)\n",
    "        self.is_container_group = True\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"ContainerGroup sum_of_loads: \" + str(self.sum_of_loads)\n",
    "\n",
    "\n",
    "class MethodGroup(Group):\n",
    "    def __init__(self, parent_load, sum_of_loads, components):\n",
    "        super().__init__(parent_load, sum_of_loads, components)\n",
    "        self.is_method_group = True\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"ContainerGroup sum_of_loads: \" + str(self.sum_of_loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES MODULES DEFINED HERE\n",
    "\n",
    "def _gen_dict_extract(key, var):\n",
    "    if hasattr(var, 'items'):\n",
    "        for k, v in var.items():\n",
    "            if k == key:\n",
    "                yield v\n",
    "            if isinstance(v, dict):\n",
    "                for result in _gen_dict_extract(key, v):\n",
    "                    yield result\n",
    "            elif isinstance(v, (list)):\n",
    "                for d in v:\n",
    "                    for result in _gen_dict_extract(key, d):\n",
    "                        yield result\n",
    "\n",
    "\n",
    "def _get_schema_only(references):\n",
    "    saved_schema = 'default'\n",
    "    for reference in references:\n",
    "        schema = reference.split(\"#/components/schemas/\")\n",
    "        try:\n",
    "            saved_schema = schema[1]\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "    return saved_schema\n",
    "\n",
    "\n",
    "def _get_schemas_only(references):\n",
    "    saved_schemas = []\n",
    "    for reference in references:\n",
    "        schema = reference.split(\"#/components/schemas/\")\n",
    "        try:\n",
    "            saved_schemas.append(schema[1])\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "    return saved_schemas\n",
    "\n",
    "\n",
    "def _join_components(threshold, components):\n",
    "    joined_components = []\n",
    "    remaining_components = []\n",
    "    collective_contribution = 0\n",
    "    for i in range(len(components)):\n",
    "        component = components[i]\n",
    "        collective_contribution += component.contribution\n",
    "\n",
    "        if collective_contribution < threshold:\n",
    "            joined_components.append(component)\n",
    "        else:\n",
    "            remaining_components.append(component)\n",
    "\n",
    "    return joined_components, remaining_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS MODULES\n",
    "\n",
    "MAX_WN_LOAD = 50\n",
    "MIN_WN_LOAD = 20\n",
    "MAX_POD_LOAD = 50\n",
    "MIN_POD_LOAD = 30\n",
    "DEFAULT_SCHEMA_NAME = 'default'\n",
    "POD_LEVEL = \"pod\"\n",
    "CL_LEVEL = \"cluster\"\n",
    "WN_LEVEL = \"worker-node\"\n",
    "SCHEMA_LEVEL = \"x-storage-level\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _derive_components(single_data_obj):\n",
    "    clusters = []\n",
    "    cls = single_data_obj[RefPath.X_CLUSTERS]\n",
    "\n",
    "    for cl in cls.values():\n",
    "        ref_path = RefPath.INITIAL + cl[\"name\"]\n",
    "        clusters.append(Cluster(cl[\"name\"], cl[\"metrics\"][\"load\"], cl, ref_path))\n",
    "\n",
    "    methods = []\n",
    "    data_paths = single_data_obj[RefPath.PATHS]\n",
    "    for path_name, path in data_paths.items():\n",
    "        for method_name, method in path.items():\n",
    "            ref_path = RefPath(method[RefPath.X_LOCATION][RefPath.REF])\n",
    "\n",
    "            all_references = list(set(_gen_dict_extract('$ref', method)))\n",
    "            schema_name = _get_schema_only(all_references)\n",
    "\n",
    "            methods.append(\n",
    "                Method(path_name, method_name, ref_path, method[\"x-metrics\"][\"load\"], schema_name, method))\n",
    "    return clusters, methods\n",
    "\n",
    "def _get_scalable_components(clusters):\n",
    "    scalable_wns = []\n",
    "    scalable_pods = []\n",
    "    for cluster in clusters:\n",
    "        for worker_node in cluster.worker_nodes:\n",
    "            if MIN_WN_LOAD < worker_node.load < MAX_WN_LOAD:\n",
    "                print(\"no need to scale \", str(worker_node))\n",
    "\n",
    "                for wn_pod in worker_node.pods:\n",
    "                    if MIN_POD_LOAD < wn_pod.load < MAX_POD_LOAD:\n",
    "                        print(\"no need to scale\", str(wn_pod))\n",
    "                    else:\n",
    "                        print(wn_pod, \" need scaling.\")\n",
    "                        scalable_pods.append(wn_pod)\n",
    "            else:\n",
    "                print(worker_node, \" need scaling.\")\n",
    "                scalable_wns.append(worker_node)\n",
    "    return scalable_wns, scalable_pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"01data.json\") as f:    \n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adjust_and_merge_pods(scalable_pods, methods):\n",
    "    min_load_pods = []\n",
    "    \n",
    "#     if there is only one pod it will return as it is\n",
    "    if len(scalable_pods) < 2:\n",
    "        return scalable_pods\n",
    "\n",
    "#     creating a new list so that we can modify the original one\n",
    "    for pod in list(scalable_pods):\n",
    "        if pod.load <= MIN_POD_LOAD:\n",
    "            min_load_pods.append(pod)            \n",
    "            scalable_pods.remove(pod)\n",
    "    \n",
    "    first_pod = scalable_pods[0]    \n",
    "    print(first_pod.full_component)\n",
    "    for pod in min_load_pods:\n",
    "        for container in pod.containers:            \n",
    "            \n",
    "            container_methods = filter(lambda method: method.ref_path.full_path == container.ref_path, methods)\n",
    "            first_pod_containers = first_pod.full_component[RefPath.CONTAINERS]\n",
    "            new_container_name = \"c\" + str((len(first_pod_containers) + 1))\n",
    "            first_pod_containers[new_container_name] = container.full_component\n",
    "\n",
    "#             don't forget to chage the id of container\n",
    "            first_pod_containers[new_container_name]['id'] = new_container_name\n",
    "    \n",
    "            for container_method in container_methods:\n",
    "                print(container_method.ref_path.full_path)\n",
    "                \n",
    "#                 getting ref_path of first container in first selected pod\n",
    "                \n",
    "                container_method.ref_path = RefPath(first_pod.containers[0].ref_path)\n",
    "                container_method.ref_path.container_name = new_container_name\n",
    "                \n",
    "                print(container_method.ref_path.full_path)\n",
    "                \n",
    "    \n",
    "    return min_load_pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'pod1', 'metrics': {'load': 51}, 'containers': {'c1': {'id': 'c1', 'metrics': {'load': 30}}, 'c2': {'id': 'c2', 'metrics': {'load': 27}}, 'c3': {'id': 'c3', 'metrics': {'load': 16}}, 'c4': {'id': 'c4', 'metrics': {'load': 13}}, 'c5': {'id': 'c28', 'metrics': {'load': 13}}, 'c6': {'id': 'c29', 'metrics': {'load': 57}}, 'c7': {'id': 'c30', 'metrics': {'load': 43}}, 'c8': {'id': 'c31', 'metrics': {'load': 7}}, 'c9': {'id': 'c28', 'metrics': {'load': 13}}, 'c10': {'id': 'c29', 'metrics': {'load': 57}}, 'c11': {'id': 'c30', 'metrics': {'load': 43}}, 'c12': {'id': 'c31', 'metrics': {'load': 7}}, 'c13': {'id': 'c28', 'metrics': {'load': 13}}, 'c14': {'id': 'c29', 'metrics': {'load': 57}}, 'c15': {'id': 'c30', 'metrics': {'load': 43}}, 'c16': {'id': 'c31', 'metrics': {'load': 7}}, 'c17': {'id': 'c28', 'metrics': {'load': 13}}, 'c18': {'id': 'c28', 'metrics': {'load': 13}}, 'c19': {'id': 'c28', 'metrics': {'load': 13}}, 'c20': {'id': 'c28', 'metrics': {'load': 13}}, 'c21': {'id': 'c29', 'metrics': {'load': 57}}, 'c22': {'id': 'c30', 'metrics': {'load': 43}}, 'c23': {'id': 'c31', 'metrics': {'load': 7}}, 'c24': {'id': 'c28', 'metrics': {'load': 13}}, 'c25': {'id': 'c29', 'metrics': {'load': 57}}, 'c26': {'id': 'c30', 'metrics': {'load': 43}}, 'c27': {'id': 'c31', 'metrics': {'load': 7}}, 'c28': {'id': 'c28', 'metrics': {'load': 13}}, 'c29': {'id': 'c29', 'metrics': {'load': 57}}, 'c30': {'id': 'c30', 'metrics': {'load': 43}}, 'c31': {'id': 'c31', 'metrics': {'load': 7}}}}\n",
      "#/info/x-clusters/cl1/worker-nodes/wn1/pods/pod3/containers/c1\n",
      "#/info/x-clusters/cl1/worker-nodes/wn1/pods/pod1/containers/c32\n",
      "#/info/x-clusters/cl1/worker-nodes/wn1/pods/pod3/containers/c2\n",
      "#/info/x-clusters/cl1/worker-nodes/wn1/pods/pod1/containers/c33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.Pod at 0x7f49b2379970>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_adjust_and_merge_pods(scalable_pods, methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_pod_containers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-d670bf24eefd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_pod_containers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'first_pod_containers' is not defined"
     ]
    }
   ],
   "source": [
    "first_pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no need to scale  wn1 ---- 40 (#/info/x-clusters/cl1/worker-nodes/wn1) New ? False\n",
      "pod1 ---- 51 (#/info/x-clusters/cl1/worker-nodes/wn1/pods/pod1) New ? False  need scaling.\n",
      "pod2 ---- 80 (#/info/x-clusters/cl1/worker-nodes/wn1/pods/pod2) New ? False  need scaling.\n",
      "pod3 ---- 30 (#/info/x-clusters/cl1/worker-nodes/wn1/pods/pod3) New ? False  need scaling.\n"
     ]
    }
   ],
   "source": [
    "clusters, methods = _derive_components(dataset[0])\n",
    "scalable_wns, scalable_pods = _get_scalable_components(clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
